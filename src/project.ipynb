{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.源数据的读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_origin = pd.read_csv('../UserBehavior.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.源数据补全列名，打印信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_origin.columns = ['UserID', 'ItemID', 'CatogoryID', 'BehaviorType', 'TimeStamps']\n",
    "df_origin.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.取百分之一用户的数据便于后续分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_Second = df_origin.dropna()\n",
    "df_Second = df_Second.drop_duplicates(subset=['UserID', 'ItemID', 'TimeStamps'])\n",
    "# select 1/100 user data\n",
    "df_Second = df_Second[df_Second['UserID'] % 100 == 0]\n",
    "df_Second.to_csv('../UserBehavior-2.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.提高时间信息的可读性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Second = pd.read_csv('../UserBehavior-2.csv')\n",
    "df_Second.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Second = pd.read_csv('../UserBehavior-2.csv')\n",
    "startTime = time.mktime(time.strptime(\"2017-11-25 00:00:00\", \"%Y-%m-%d %H:%M:%S\"))\n",
    "endTime = time.mktime(time.strptime(\"2017-12-3 23:59:59\", \"%Y-%m-%d %H:%M:%S\"))\n",
    "df_Second = df_Second.loc[(df_Second['TimeStamps'] >= startTime) & (df_Second['TimeStamps'] <= endTime)]\n",
    "\n",
    "\n",
    "df_Second[\"time\"] = df_Second[\"TimeStamps\"].apply(lambda x: time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(x)))\n",
    "df_Second['weekday'] = pd.to_datetime(df_Second['time'], format=\"%Y-%m-%d %H:%M:%S\").dt.day_name()\n",
    "df_Second['date'] = df_Second['time'].str[0:10]\n",
    "df_Second['date'] = pd.to_datetime(df_Second['date'], format='%Y-%m-%d')\n",
    "df_Second['time'] = df_Second['time'].str[11:13]\n",
    "df_Second['time'] = df_Second['time'].astype(int)\n",
    "df_Second['hour'] = pd.cut(df_Second['time'], bins=[-1, 5, 10, 13, 18, 24], labels=['morning', 'forenoon', 'noon', 'afternoon', 'night'])\n",
    "df_Second = df_Second.drop(columns=['Unnamed: 0','time'])\n",
    "df_Second.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.数据验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_Second.duplicated().any())\n",
    "print(df_Second.isnull().any())\n",
    "print(df_Second.date.min())\n",
    "print(df_Second.date.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 6.商品分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# (计算每个商品的行为总量以及转化率)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_item = df_Second[['ItemID','CatogoryID']].drop_duplicates()\n",
    "df_item_top=pd.pivot_table(df_Second,values=\"UserID\",columns=\"BehaviorType\",index=\"ItemID\",aggfunc=\"count\").sort_values(by=[\"buy\"],ascending=False)\n",
    "df_item_top['buy'] = df_item_top['buy'].fillna(0)\n",
    "df_item_top['cart'] = df_item_top['cart'].fillna(0)\n",
    "df_item_top['fav'] = df_item_top['fav'].fillna(0)\n",
    "df_item_top['pv'] = df_item_top['pv'].fillna(0)\n",
    "df_item_top['转化率']=df_item_top['buy']/df_item_top['pv']\n",
    "df_item_top['转化率'] = df_item_top['转化率'].fillna(0)\n",
    "df_item_top['转化率']=df_item_top['转化率'].apply(lambda x: format(x, '.2%'))\n",
    "df_item = pd.merge(df_item,df_item_top,how='left',on='ItemID')\n",
    "df_item.to_csv('../Item.csv')\n",
    "df_item.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 7.用户行为分析"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# (检查各行为占比)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "type = df_Second.groupby(by='BehaviorType').count()['UserID']\n",
    "plt.bar(type.index,type.values)\n",
    "type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# (根据日期，时间对行为进行分析)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "day_pv_count = df_Second[df_Second['BehaviorType']=='pv'].groupby(by='date').count()\n",
    "day_fav_count = df_Second[df_Second['BehaviorType']=='fav'].groupby(by='date').count()\n",
    "day_cart_count = df_Second[df_Second['BehaviorType']=='cart'].groupby(by='date').count()\n",
    "day_buy_count = df_Second[df_Second['BehaviorType']=='buy'].groupby(by='date').count()\n",
    "#把用户行为根据天数分割\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(list(day_pv_count['BehaviorType'].index),list(day_pv_count['BehaviorType'].values),linestyle='--',color='black')\n",
    "plt.plot(list(day_fav_count['BehaviorType'].index),list(day_fav_count['BehaviorType'].values),linestyle='--',color='blue')\n",
    "plt.plot(list(day_cart_count['BehaviorType'].index),list(day_cart_count['BehaviorType'].values),linestyle='--',color='green')\n",
    "plt.plot(list(day_buy_count['BehaviorType'].index),list(day_buy_count['BehaviorType'].values),linestyle='--',color='red')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(list(day_fav_count['BehaviorType'].index),list(day_fav_count['BehaviorType'].values),linestyle='--',color='blue')\n",
    "plt.plot(list(day_cart_count['BehaviorType'].index),list(day_cart_count['BehaviorType'].values),linestyle='--',color='green')\n",
    "plt.plot(list(day_buy_count['BehaviorType'].index),list(day_buy_count['BehaviorType'].values),linestyle='--',color='red')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "#把用户行为根据时间分割，第二张图不包括点击量的数据\n",
    "day_pv_count = df_Second[df_Second['BehaviorType']=='pv'].groupby(by='hour').count()\n",
    "day_fav_count = df_Second[df_Second['BehaviorType']=='fav'].groupby(by='hour').count()\n",
    "day_cart_count = df_Second[df_Second['BehaviorType']=='cart'].groupby(by='hour').count()\n",
    "day_buy_count = df_Second[df_Second['BehaviorType']=='buy'].groupby(by='hour').count()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(list(day_pv_count['BehaviorType'].index),list(day_pv_count['BehaviorType'].values),linestyle='--',color='black')\n",
    "plt.plot(list(day_fav_count['BehaviorType'].index),list(day_fav_count['BehaviorType'].values),linestyle='--',color='blue')\n",
    "plt.plot(list(day_cart_count['BehaviorType'].index),list(day_cart_count['BehaviorType'].values),linestyle='--',color='green')\n",
    "plt.plot(list(day_buy_count['BehaviorType'].index),list(day_buy_count['BehaviorType'].values),linestyle='--',color='red')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(list(day_fav_count['BehaviorType'].index),list(day_fav_count['BehaviorType'].values),linestyle='--',color='blue')\n",
    "plt.plot(list(day_cart_count['BehaviorType'].index),list(day_cart_count['BehaviorType'].values),linestyle='--',color='green')\n",
    "plt.plot(list(day_buy_count['BehaviorType'].index),list(day_buy_count['BehaviorType'].values),linestyle='--',color='red')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "#提取每个用户的浏览，收藏，加购物车，购买数据，第二张图不包括浏览的数据"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# (整理每个用户的行为习惯)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_user = df_Second['UserID'].drop_duplicates()\n",
    "df_pv = df_Second.loc[df_Second['BehaviorType']=='pv',['UserID','ItemID', 'CatogoryID']]\n",
    "df_fav = df_Second.loc[df_Second['BehaviorType']=='fav',['UserID','ItemID', 'CatogoryID']]\n",
    "df_cart = df_Second.loc[df_Second['BehaviorType']=='cart',['UserID','ItemID', 'CatogoryID']]\n",
    "df_buy = df_Second.loc[df_Second['BehaviorType']=='buy',['UserID','ItemID', 'CatogoryID']]\n",
    "#把每个用户最多浏览的商品类数据整理出来\n",
    "\n",
    "df_pv_count = df_pv.groupby(['UserID','CatogoryID']).ItemID.count().reset_index()\n",
    "df_pv_count.rename(columns={'ItemID':'CatogoryCounts'},inplace=True)\n",
    "df_pv_max = df_pv_count.groupby('UserID').CatogoryCounts.max().reset_index()\n",
    "df_pv_max.rename(columns={'CatogoryCounts':'FavoriteCatogory'},inplace=True)\n",
    "df_pv_count= pd.merge(df_pv_count,df_pv_max,how='left',on='UserID')\n",
    "df_pv_count['CatogoryID']=df_pv_count['CatogoryID'].astype(str)\n",
    "df_pv = df_pv_count.loc[df_pv_count['CatogoryCounts']==df_pv_count['FavoriteCatogory'],'CatogoryID'].groupby(df_pv_count['UserID']).aggregate(lambda x:','.join(x)).reset_index()\n",
    "df_user = pd.merge(df_user,df_pv,how='left',on='UserID')\n",
    "df_user.rename(columns={'CatogoryID':'MostPvCatogory'},inplace=True)\n",
    "#把每个用户最多加购物车的商品类数据整理出来\n",
    "\n",
    "df_fav_count = df_fav.groupby(['UserID','CatogoryID']).ItemID.count().reset_index()\n",
    "df_fav_count.rename(columns={'ItemID':'CatogoryCounts'},inplace=True)\n",
    "df_fav_max = df_fav_count.groupby('UserID').CatogoryCounts.max().reset_index()\n",
    "df_fav_max.rename(columns={'CatogoryCounts':'FavoriteCatogory'},inplace=True)\n",
    "df_fav_count= pd.merge(df_fav_count,df_fav_max,how='left',on='UserID')\n",
    "df_fav_count['CatogoryID']=df_fav_count['CatogoryID'].astype(str)\n",
    "df_fav = df_fav_count.loc[df_fav_count['CatogoryCounts']==df_fav_count['FavoriteCatogory'],'CatogoryID'].groupby(df_fav_count['UserID']).aggregate(lambda x:','.join(x)).reset_index()\n",
    "df_user = pd.merge(df_user,df_fav,how='left',on='UserID')\n",
    "df_user.rename(columns={'CatogoryID':'MostFavCatogory'},inplace=True)\n",
    "#把每个用户最多收藏的商品类数据整理出来\n",
    "\n",
    "df_cart_count = df_cart.groupby(['UserID','CatogoryID']).ItemID.count().reset_index()\n",
    "df_cart_count.rename(columns={'ItemID':'CatogoryCounts'},inplace=True)\n",
    "df_cart_max = df_cart_count.groupby('UserID').CatogoryCounts.max().reset_index()\n",
    "df_cart_max.rename(columns={'CatogoryCounts':'FavoriteCatogory'},inplace=True)\n",
    "df_cart_count= pd.merge(df_cart_count,df_cart_max,how='left',on='UserID')\n",
    "df_cart_count['CatogoryID']=df_cart_count['CatogoryID'].astype(str)\n",
    "df_cart = df_cart_count.loc[df_cart_count['CatogoryCounts']==df_cart_count['FavoriteCatogory'],'CatogoryID'].groupby(df_cart_count['UserID']).aggregate(lambda x:','.join(x)).reset_index()\n",
    "df_user = pd.merge(df_user,df_cart,how='left',on='UserID')\n",
    "df_user.rename(columns={'CatogoryID':'MostCartCatogory'},inplace=True)\n",
    "#把每个用户最多购买的商品类数据整理出来\n",
    "\n",
    "df_buy_count = df_buy.groupby(['UserID','CatogoryID']).ItemID.count().reset_index()\n",
    "df_buy_count.rename(columns={'ItemID':'CatogoryCounts'},inplace=True)\n",
    "df_buy_max = df_buy_count.groupby('UserID').CatogoryCounts.max().reset_index()\n",
    "df_buy_max.rename(columns={'CatogoryCounts':'FavoriteCatogory'},inplace=True)\n",
    "df_buy_count= pd.merge(df_buy_count,df_buy_max,how='left',on='UserID')\n",
    "df_buy_count['CatogoryID']=df_buy_count['CatogoryID'].astype(str)\n",
    "df_buy = df_buy_count.loc[df_buy_count['CatogoryCounts']==df_buy_count['FavoriteCatogory'],'CatogoryID'].groupby(df_buy_count['UserID']).aggregate(lambda x:','.join(x)).reset_index()\n",
    "df_user = pd.merge(df_user,df_buy,how='left',on='UserID')\n",
    "df_user.rename(columns={'CatogoryID':'MostBuyCatogory'},inplace=True)\n",
    "df_user = df_user.fillna(0)\n",
    "#填充空值为0\n",
    "df_user.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (用户操作时间差分析)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the avarage time to buy items from cart to buy\n",
    "df_pv = df_Second.loc[df_Second['BehaviorType']=='pv',['UserID','ItemID','TimeStamps']]\n",
    "df_fav = df_Second.loc[df_Second['BehaviorType']=='fav',['UserID','ItemID','TimeStamps']]\n",
    "df_cart = df_Second.loc[df_Second['BehaviorType']=='cart',['UserID','ItemID','TimeStamps']]\n",
    "df_buy = df_Second.loc[df_Second['BehaviorType']=='buy',['UserID','ItemID','TimeStamps']]\n",
    "\n",
    "buy_cart=pd.merge(df_cart,df_buy,how='inner',on=['UserID','ItemID'],suffixes=('_cart','_buy'))\n",
    "buy_cart[\"time\"]=buy_cart[\"TimeStamps_buy\"]-buy_cart[\"TimeStamps_cart\"]\n",
    "\n",
    "buy_cart_time = buy_cart.loc[buy_cart['time']>0,'time'].mean()\n",
    "print(\"所有商品从加入购物车到被买下的平均时间\",int(buy_cart_time),\"s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the avarage time to buy items from pv to buy\n",
    "df_pv = df_Second.loc[df_Second['BehaviorType']=='pv',['UserID','ItemID','TimeStamps']]\n",
    "df_fav = df_Second.loc[df_Second['BehaviorType']=='fav',['UserID','ItemID','TimeStamps']]\n",
    "df_cart = df_Second.loc[df_Second['BehaviorType']=='cart',['UserID','ItemID','TimeStamps']]\n",
    "df_buy = df_Second.loc[df_Second['BehaviorType']=='buy',['UserID','ItemID','TimeStamps']]\n",
    "\n",
    "df_pv=df_pv.groupby(['UserID','ItemID']).TimeStamps.min().reset_index().rename(columns={'TimeStamps':'TimeStamps'})\n",
    "buy_pv=pd.merge(df_pv,df_buy,how='inner',on=['UserID','ItemID'],suffixes=('_pv','_buy'))\n",
    "buy_pv[\"time\"]=buy_pv[\"TimeStamps_buy\"]-buy_pv[\"TimeStamps_pv\"]\n",
    "buy_pv_time = buy_pv.loc[buy_pv['time']>0,'time'].mean()\n",
    "print(\"所有商品从第一次浏览到被买下的平均时间\",int(buy_pv_time),\"s\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# (用户活跃时间段分析)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 购买时间段\n",
    "time_buy = df_Second[df_Second['BehaviorType']=='buy'].groupby(['UserID','hour']).ItemID.count().reset_index()\n",
    "time_buy.rename(columns={'ItemID':'hour_counts'},inplace=True)\n",
    "time_buy_max = time_buy.groupby('UserID').hour_counts.max().reset_index()\n",
    "time_buy_max.rename(columns={'hour_counts':'buy_counts_max'},inplace=True)\n",
    "time_buy = pd.merge(time_buy,time_buy_max,how='left',on='UserID')\n",
    "time_buy_hour = time_buy.loc[time_buy['hour_counts']==time_buy['buy_counts_max'],['hour','UserID']].groupby(time_buy['UserID']).aggregate(lambda x:','.join(x)).reset_index()\n",
    "df_user = pd.merge(df_user,time_buy_hour,how = 'left',on='UserID')\n",
    "df_user.rename(columns={'hour':'timeBuy'},inplace=True)\n",
    "\n",
    "## 购买周几\n",
    "week_buy=df_Second[df_Second['BehaviorType']=='buy'].groupby(['UserID','weekday']).ItemID.count().reset_index()\n",
    "week_buy.rename(columns={'ItemID':'week_counts'},inplace=True)\n",
    "week_buy_max = week_buy.groupby('UserID').week_counts.max().reset_index()\n",
    "week_buy_max.rename(columns={'week_counts':'week_counts_max'},inplace=True)\n",
    "week_buy = pd.merge(week_buy,week_buy_max,how='left',on='UserID')\n",
    "week_buy['weekday']=week_buy['weekday'].astype(str)\n",
    "week_buy_date=week_buy.loc[week_buy['week_counts']==week_buy['week_counts_max'],'weekday'].groupby(week_buy['UserID']).aggregate(lambda x:','.join(x)).reset_index()\n",
    "week_buy_date.head()\n",
    "df_user = pd.merge(df_user,week_buy_date,how = 'left',on='UserID')\n",
    "df_user.rename(columns={'weekday':'weekBuy'},inplace=True)\n",
    "\n",
    "## 浏览时间段\n",
    "time_browser = df_Second[df_Second['BehaviorType']=='pv'].groupby(['UserID','hour']).ItemID.count().reset_index()\n",
    "time_browser.rename(columns={'ItemID':'hour_counts'},inplace=True)\n",
    "time_browser_max = time_browser.groupby('UserID').hour_counts.max().reset_index()\n",
    "time_browser_max.rename(columns={'hour_counts':'browser_counts_max'},inplace=True)\n",
    "time_browser = pd.merge(time_browser,time_browser_max,how='left',on='UserID')\n",
    "time_browser_hour = time_browser.loc[time_browser['hour_counts']==time_browser['browser_counts_max'],['hour','UserID']].groupby(time_browser['UserID']).aggregate(lambda x:','.join(x)).reset_index()\n",
    "df_user = pd.merge(df_user,time_browser_hour,how = 'left',on='UserID')\n",
    "df_user.rename(columns={'hour':'timebrowser'},inplace=True)\n",
    "time_browser_hour.head()\n",
    "time_buy_hour.head()\n",
    "## 购买周几\n",
    "week_browser=df_Second[df_Second['BehaviorType']=='pv'].groupby(['UserID','weekday']).ItemID.count().reset_index()\n",
    "week_browser.rename(columns={'ItemID':'week_counts'},inplace=True)\n",
    "week_browser_max = week_browser.groupby('UserID').week_counts.max().reset_index()\n",
    "week_browser_max.rename(columns={'week_counts':'week_counts_max'},inplace=True)\n",
    "week_browser = pd.merge(week_browser,week_browser_max,how='left',on='UserID')\n",
    "week_browser['weekday']=week_browser['weekday'].astype(str)\n",
    "week_browser_date=week_browser.loc[week_browser['week_counts']==week_browser['week_counts_max'],'weekday'].groupby(week_browser['UserID']).aggregate(lambda x:','.join(x)).reset_index()\n",
    "df_user = pd.merge(df_user,week_browser_date,how = 'left',on='UserID')\n",
    "df_user.rename(columns={'weekday':'weekbrowser'},inplace=True)\n",
    "df_user = df_user.fillna(0)\n",
    "df_user.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.建立用户的RFM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_buy_1 = df_Second[df_Second['BehaviorType']=='buy']\n",
    "df_buy_1.head()\n",
    "Near_buy_tstamp = df_buy_1.groupby(by='UserID')['TimeStamps'].max() #得出用户最近购买时间\n",
    "df_buy_1 = pd.DataFrame(data=Near_buy_tstamp)\n",
    "diff_time = (endTime - Near_buy_tstamp).astype('int') #用户最近购买时间距离结束时间长短\n",
    "diff_day = (diff_time/(24*60*60)).astype('int')\n",
    "df_user['diffDay'] = diff_day\n",
    "df_user['diffDay'] = df_user['diffDay'].fillna(7)\n",
    "\n",
    "\n",
    "df_buy_2 = df_Second[df_Second['BehaviorType']=='buy']\n",
    "df_cart_2 = df_Second[df_Second['BehaviorType']=='cart']\n",
    "\n",
    "df_user['Frequency'] = df_buy_2['UserID'].value_counts().astype('int')\n",
    "df_user['Frequency'] = df_user['Frequency'].fillna(0)\n",
    "\n",
    "df_user['MonetaryValue'] = df_buy_2['UserID'].value_counts().astype('int') / df_cart_2['UserID'].value_counts().astype('int')\n",
    "df_user['MonetaryValue'] = df_user['MonetaryValue'].fillna(0)\n",
    "\n",
    "RFM = df_user[['UserID','diffDay','Frequency','MonetaryValue']]\n",
    "RFM.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 8.对用户进行聚类分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RFM = RFM.replace(0, 0.01)\n",
    "RFM_log = RFM[['diffDay','Frequency','MonetaryValue']].apply(np.log,axis=1).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(RFM_log)\n",
    "RFM_normalization = scaler.transform(RFM_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# (使用肘部法则进行分析)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import subplots\n",
    "from sklearn.cluster import KMeans\n",
    "ks = range(1,9)\n",
    "inertias=[]\n",
    "for k in  ks:\n",
    "    kc = KMeans(n_clusters=k, init='k-means++', random_state = 1)\n",
    "    kc.fit(RFM_normalization)\n",
    "    inertias.append(kc.inertia_)\n",
    "\n",
    "    print('k=',k,' 迭代次数',kc.n_iter_)\n",
    "\n",
    "f,ax = subplots(figsize=(10,6))\n",
    "plt.plot(ks, inertias,'-o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Sum of squared distances')\n",
    "plt.title('Elbow Criterion method to find best k')\n",
    "\n",
    "from sklearn import metrics\n",
    "kk = range(2,9)\n",
    "for k in kk:\n",
    "    y_pred = KMeans(n_clusters=k, random_state=1).fit_predict(RFM_normalization)\n",
    "    calinski = metrics.calinski_harabasz_score(RFM_normalization, y_pred)\n",
    "    print('k:',k,'   calinski=',calinski)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# （选定聚类数目K， 继续进行聚类）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kc = KMeans(n_clusters=3, random_state=1).fit(RFM_normalization)\n",
    "\n",
    "cluster_label = kc.labels_\n",
    "RFM['K-means_label'] = cluster_label\n",
    "RFM.groupby(['K-means_label']).agg({'diffDay':'mean','Frequency':'mean','MonetaryValue':['mean','count']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RFM = RFM.drop(columns=['diffDay', 'Frequency', 'MonetaryValue'])\n",
    "df_user = pd.merge(df_user,RFM,how='left',on='UserID')\n",
    "df_user.rename(columns={'K-means_label':'UserLevel'},inplace=True)\n",
    "df_user['UserLevel'] = df_user['UserLevel'].replace(0,'一般用户')\n",
    "df_user['UserLevel'] = df_user['UserLevel'].replace(1,'发展用户')\n",
    "df_user['UserLevel'] = df_user['UserLevel'].replace(2,'重要用户')\n",
    "df_user.to_csv('../User.csv')\n",
    "df_user.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 9.商品推荐"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# (指定用户，获得相似的用户和用户相似度)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "user_id=100\n",
    "user_pv=df_Second[df_Second['UserID']==user_id]['ItemID'].value_counts().reset_index()\n",
    "user_pv.rename(columns={'ItemID':'pv_counts','index':'ItemID'},inplace=True)\n",
    "\n",
    "# 获得相似的用户和用户相似度\n",
    "sim_user=pd.merge(user_pv,df_Second[['UserID', 'ItemID']],how='inner',on=['ItemID'])\n",
    "sim_user_pv=sim_user.groupby('UserID').sum()['pv_counts'].reset_index()\n",
    "sim_user_pv.sort_values(by='pv_counts',ascending=False,inplace=True)\n",
    "sim_user_pv=sim_user_pv.reset_index(drop=True).rename(columns={'pv_counts':'similarity'})\n",
    "sim_user_pv=sim_user_pv.loc[sim_user_pv['UserID']!=user_id]\n",
    "sim_user_pv.loc[0]=[100,15]\n",
    "sim_user_pv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# (根据相似用户计算相似商品)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 根据相似用户计算相似商品\n",
    "sim_item=pd.merge(sim_user_pv,df_Second[['UserID', 'ItemID','CatogoryID']],how='inner',on=['UserID'])\n",
    "sim_item\n",
    "sim_item_pv=sim_item.groupby('ItemID').sum()['similarity'].reset_index()\n",
    "sim_item.drop(sim_item.columns[[0,1]], axis=1, inplace=True)\n",
    "sim_item_pv=pd.merge(sim_item_pv,sim_item,how='left',on='ItemID')\n",
    "sim_item_pv\n",
    "sim_item_pv.sort_values(by='similarity',ascending=False,inplace=True)\n",
    "sim_item_pv=sim_item_pv.reset_index(drop=True)\n",
    "sim_item_pv.drop_duplicates(subset=None, keep='first', inplace=True)\n",
    "sim_item_pv[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# (更进一步，提取相似度后根据关联规则计算商品)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#根据关联规则计算商品\n",
    "df_buy = df_Second.loc[df_Second['BehaviorType']=='buy',['UserID','ItemID', 'CatogoryID']]\n",
    "df_buy_count = df_buy.groupby(['UserID','CatogoryID']).ItemID.count().reset_index()\n",
    "df_buy_count.rename(columns={'ItemID':'CatogoryCounts'},inplace=True)\n",
    "\n",
    "df_buy_count\n",
    "df_buyy=df_buy_count.groupby('UserID').sum()\n",
    "df_buy_count= pd.merge(df_buy_count,df_buyy,how='left',on='UserID')\n",
    "df_buy_count.drop(df_buy_count.columns[[3]], axis=1, inplace=True)\n",
    "#df_buy_count= pd.merge(df_buy_count,sim_item_pv,how='left',on='UserID')\n",
    "\n",
    "df_buy_count.rename(columns={'CatogoryID_x':'CatogoryID'},inplace=True)\n",
    "df_buy_count=df_buy_count[df_buy_count.UserID.isin(sim_user_pv.UserID)]\n",
    "df_buy_count.rename(columns={'CatogoryID_x':'CatogoryID'},inplace=True)\n",
    "df_buy_count= pd.merge(df_buy_count,sim_user_pv,how='left',on='UserID')\n",
    "df_buy_count['CASIM']=df_buy_count['similarity'].astype('float')*df_buy_count['CatogoryCounts_x'].astype('float')/df_buy_count['CatogoryCounts_y'].astype('float')\n",
    "df_it=df_buy_count.groupby('CatogoryID').mean()\n",
    "df_it.drop(df_it.columns[[1,2,3]], axis=1, inplace=True)\n",
    "df_item_sim=pd.merge(sim_item_pv,df_it,how='left',on='CatogoryID')\n",
    "df_item_sim.fillna(1.0,inplace=True)\n",
    "df_item_sim['similarity']=df_item_sim['similarity'].astype('float')*df_item_sim['CASIM'].astype('float')\n",
    "df_item_sim.sort_values(by='similarity',ascending=False,inplace=True)\n",
    "df_item_sim.drop(df_item_sim.columns[[2,3,4]], axis=1, inplace=True)\n",
    "df_item_sim[0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 10.数据可视化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Pie, Funnel\n",
    "from pyecharts.render import make_snapshot\n",
    "from snapshot_selenium import snapshot\n",
    "\n",
    "\n",
    "jiti = ['一般用户', '发展用户', '重要用户']\n",
    "num = [335521,484401,168069]\n",
    "c = (\n",
    "    Pie()\n",
    "    .add(\"客户占比\", [list(z) for z in zip(jiti,num)])\n",
    "    .set_global_opts(title_opts=opts.TitleOpts(title=\"客户数量占比\"))\n",
    "    .set_series_opts(label_opts=opts.LabelOpts(formatter=\"{b}: {c}\"))\n",
    "    .render(\"pie_daishi_user.html\")\n",
    ")\n",
    "\n",
    "make_snapshot(snapshot,c,'客户数量占比.png')\n",
    "\n",
    "\n",
    "jiti = ['浏览', '收藏和加购物车', '购买']\n",
    "num = [100,9.3,2.2]\n",
    "\n",
    "c = (\n",
    "    Funnel()\n",
    "    .add(\"占比\", [list(z) for z in zip(jiti,num)])\n",
    "    .set_global_opts(title_opts=opts.TitleOpts(title=\"用户漏斗转换模型\"))\n",
    "    .set_series_opts(label_opts=opts.LabelOpts(formatter=\"{c} %\"))\n",
    "    .render(\"pie_daishi_trans.html\")\n",
    ")\n",
    "\n",
    "make_snapshot(snapshot,c,'用户转化比例.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pyecharts.options as opts\n",
    "from pyecharts.charts import Line\n",
    "x=['11-25','11-26','11-27','11-28','11-29','11-30','12-01','12-02','12-03']\n",
    "y1=[9353415, 9567422, 9041186, 8842932, 9210818, 9358998, 9718956, 12329640, 12237300]\n",
    "y2=[302071, 308954, 291221, 289100, 298587, 302264, 307115, 396749, 392197]\n",
    "y3=[563376, 582581, 541904, 534157, 551593, 565015, 623346, 793568, 774905]\n",
    "y4=[201144, 205638, 226834, 211997, 223068, 221459, 210010, 257903, 257754]\n",
    "line_1=(\n",
    "    Line()\n",
    "    .add_xaxis(xaxis_data=x)\n",
    "    .add_yaxis(series_name=\"浏览\",y_axis=y1)\n",
    "    .add_yaxis(series_name=\"收藏\",y_axis=y2)\n",
    "    .add_yaxis(series_name=\"加购\",y_axis=y3)\n",
    "    .add_yaxis(series_name=\"购买\",y_axis=y4)\n",
    "    .set_global_opts(title_opts=opts.TitleOpts(title=\"各行为数量\"))\n",
    "    .render(\"pie_daishi_1.html\")\n",
    ")\n",
    "line_2=(\n",
    "    Line()\n",
    "    .add_xaxis(xaxis_data=x)\n",
    "    .add_yaxis(series_name=\"收藏\",y_axis=y2)\n",
    "    .add_yaxis(series_name=\"加购\",y_axis=y3)\n",
    "    .add_yaxis(series_name=\"购买\",y_axis=y4)\n",
    "    .set_global_opts(title_opts=opts.TitleOpts(title=\"各行为数量\"))\n",
    "    .render(\"pie_daishi_2.html\")\n",
    ")\n",
    "make_snapshot(snapshot,line_1,'Day统计_1.png')\n",
    "make_snapshot(snapshot,line_2,'Day统计_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pyecharts.options as opts\n",
    "from pyecharts.charts import Line\n",
    "x=['morning','forenoon','noon','afternoon','night']\n",
    "y1=[6804190, 14561262, 13123245, 22573411, 32598559]\n",
    "y2=[237015, 494639, 437118, 719497, 999989]\n",
    "y3=[411727, 917240, 796471, 1348932, 2056075]\n",
    "y4=[115864, 344675, 364063, 558550, 632655]\n",
    "line_1=(\n",
    "    Line()\n",
    "    .add_xaxis(xaxis_data=x)\n",
    "    .add_yaxis(series_name=\"浏览\",y_axis=y1)\n",
    "    .add_yaxis(series_name=\"收藏\",y_axis=y2)\n",
    "    .add_yaxis(series_name=\"加购\",y_axis=y3)\n",
    "    .add_yaxis(series_name=\"购买\",y_axis=y4)\n",
    "    .set_global_opts(title_opts=opts.TitleOpts(title=\"各行为数量\"))\n",
    "    .render(\"pie_daishi_3.html\")\n",
    ")\n",
    "line_2=(\n",
    "    Line()\n",
    "    .add_xaxis(xaxis_data=x)\n",
    "    .add_yaxis(series_name=\"收藏\",y_axis=y2)\n",
    "    .add_yaxis(series_name=\"加购\",y_axis=y3)\n",
    "    .add_yaxis(series_name=\"购买\",y_axis=y4)\n",
    "    .set_global_opts(title_opts=opts.TitleOpts(title=\"各行为数量\"))\n",
    "    .render(\"pie_daishi_4.html\")\n",
    ")\n",
    "make_snapshot(snapshot,line_1,'Hour统计_1.png')\n",
    "make_snapshot(snapshot,line_2,'Hour统计_2.png')\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}