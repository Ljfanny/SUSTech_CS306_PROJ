{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from matplotlib import pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.源数据的读取"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_origin = pd.read_csv('../UserBehavior.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.源数据补全列名，打印信息"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_origin.columns = ['UserID', 'ItemID', 'CatogoryID', 'BehaviorType', 'TimeStamps']\n",
    "df_origin.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.取百分之一用户的数据便于后续分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df_Second = df_origin.dropna()\n",
    "df_Second = df_Second.drop_duplicates(subset=['UserID', 'ItemID', 'TimeStamps'])\n",
    "# select 1/100 user data\n",
    "# df_Second = df_Second[df_Second['UserID'] % 100 == 0]\n",
    "df_Second.to_csv('../UserBehavior-2.csv')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.提高时间信息的可读性"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_Second = pd.read_csv('../UserBehavior-2.csv')\n",
    "startTime = time.mktime(time.strptime(\"2017-11-25 00:00:00\", \"%Y-%m-%d %H:%M:%S\"))\n",
    "endTime = time.mktime(time.strptime(\"2017-12-3 23:59:59\", \"%Y-%m-%d %H:%M:%S\"))\n",
    "df_Second = df_Second.loc[(df_Second['TimeStamps'] >= startTime) & (df_Second['TimeStamps'] <= endTime)]\n",
    "\n",
    "\n",
    "df_Second[\"time\"] = df_Second[\"TimeStamps\"].apply(lambda x: time.strftime('%Y-%m-%d %H:%M:%S', time.localtime(x)))\n",
    "df_Second['weekday'] = pd.to_datetime(df_Second['time'], format=\"%Y-%m-%d %H:%M:%S\").dt.day_name()\n",
    "df_Second['date'] = df_Second['time'].str[0:10]\n",
    "df_Second['date'] = pd.to_datetime(df_Second['date'], format='%Y-%m-%d')\n",
    "df_Second['time'] = df_Second['time'].str[11:13]\n",
    "df_Second['time'] = df_Second['time'].astype(int)\n",
    "df_Second['hour'] = pd.cut(df_Second['time'], bins=[-1, 5, 10, 13, 18, 24], labels=['morning', 'forenoon', 'noon', 'afternoon', 'night'])\n",
    "df_Second = df_Second.drop(columns=['time'])\n",
    "\n",
    "df_Second.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.数据验证"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_Second.duplicated().any())\n",
    "print(df_Second.isnull().any())\n",
    "print(df_Second.date.min())\n",
    "print(df_Second.date.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bt_persent = df_Second.groupby(by='BehaviorType')['UserID'].nunique() / df_Second.groupby(by='BehaviorType')['UserID'].nunique().sum()*100\n",
    "plt.bar(bt_persent.index,bt_persent.values)\n",
    "bt_persent"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# 6.用户行为分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "#把用户行为根据天数分割\n",
    "day_pv_count = df_Second[df_Second['BehaviorType']=='pv'].groupby(by='date').count()\n",
    "day_fav_count = df_Second[df_Second['BehaviorType']=='fav'].groupby(by='date').count()\n",
    "day_cart_count = df_Second[df_Second['BehaviorType']=='cart'].groupby(by='date').count()\n",
    "day_buy_count = df_Second[df_Second['BehaviorType']=='buy'].groupby(by='date').count()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(list(day_pv_count['BehaviorType'].index),list(day_pv_count['BehaviorType'].values),linestyle='--',color='black')\n",
    "plt.plot(list(day_fav_count['BehaviorType'].index),list(day_fav_count['BehaviorType'].values),linestyle='--',color='blue')\n",
    "plt.plot(list(day_cart_count['BehaviorType'].index),list(day_cart_count['BehaviorType'].values),linestyle='--',color='green')\n",
    "plt.plot(list(day_buy_count['BehaviorType'].index),list(day_buy_count['BehaviorType'].values),linestyle='--',color='red')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(list(day_fav_count['BehaviorType'].index),list(day_fav_count['BehaviorType'].values),linestyle='--',color='blue')\n",
    "plt.plot(list(day_cart_count['BehaviorType'].index),list(day_cart_count['BehaviorType'].values),linestyle='--',color='green')\n",
    "plt.plot(list(day_buy_count['BehaviorType'].index),list(day_buy_count['BehaviorType'].values),linestyle='--',color='red')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "#把用户行为根据时间分割，第二张图不包括点击量的数据\n",
    "day_pv_count = df_Second[df_Second['BehaviorType']=='pv'].groupby(by='hour').count()\n",
    "day_fav_count = df_Second[df_Second['BehaviorType']=='fav'].groupby(by='hour').count()\n",
    "day_cart_count = df_Second[df_Second['BehaviorType']=='cart'].groupby(by='hour').count()\n",
    "day_buy_count = df_Second[df_Second['BehaviorType']=='buy'].groupby(by='hour').count()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(list(day_pv_count['BehaviorType'].index),list(day_pv_count['BehaviorType'].values),linestyle='--',color='black')\n",
    "plt.plot(list(day_fav_count['BehaviorType'].index),list(day_fav_count['BehaviorType'].values),linestyle='--',color='blue')\n",
    "plt.plot(list(day_cart_count['BehaviorType'].index),list(day_cart_count['BehaviorType'].values),linestyle='--',color='green')\n",
    "plt.plot(list(day_buy_count['BehaviorType'].index),list(day_buy_count['BehaviorType'].values),linestyle='--',color='red')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(list(day_fav_count['BehaviorType'].index),list(day_fav_count['BehaviorType'].values),linestyle='--',color='blue')\n",
    "plt.plot(list(day_cart_count['BehaviorType'].index),list(day_cart_count['BehaviorType'].values),linestyle='--',color='green')\n",
    "plt.plot(list(day_buy_count['BehaviorType'].index),list(day_buy_count['BehaviorType'].values),linestyle='--',color='red')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "#提取每个用户的浏览，收藏，加购物车，购买数据，第二张图不包括浏览的数据\n",
    "\n",
    "df_user = df_Second['UserID'].drop_duplicates()\n",
    "df_pv = df_Second.loc[df_Second['BehaviorType']=='pv',['UserID','ItemID', 'CatogoryID']]\n",
    "df_fav = df_Second.loc[df_Second['BehaviorType']=='fav',['UserID','ItemID', 'CatogoryID']]\n",
    "df_cart = df_Second.loc[df_Second['BehaviorType']=='cart',['UserID','ItemID', 'CatogoryID']]\n",
    "df_buy = df_Second.loc[df_Second['BehaviorType']=='buy',['UserID','ItemID', 'CatogoryID']]\n",
    "#把每个用户最多浏览的商品类数据整理出来\n",
    "\n",
    "df_pv_count = df_pv.groupby(['UserID','CatogoryID']).ItemID.count().reset_index()\n",
    "df_pv_count.rename(columns={'ItemID':'CatogoryCounts'},inplace=True)\n",
    "df_pv_max = df_pv_count.groupby('UserID').CatogoryCounts.max().reset_index()\n",
    "df_pv_max.rename(columns={'CatogoryCounts':'FavoriteCatogory'},inplace=True)\n",
    "df_pv_count= pd.merge(df_pv_count,df_pv_max,how='left',on='UserID')\n",
    "df_pv_count['CatogoryID']=df_pv_count['CatogoryID'].astype(str)\n",
    "df_pv = df_pv_count.loc[df_pv_count['CatogoryCounts']==df_pv_count['FavoriteCatogory'],'CatogoryID'].groupby(df_pv_count['UserID']).aggregate(lambda x:','.join(x)).reset_index()\n",
    "df_user = pd.merge(df_user,df_pv,how='left',on='UserID')\n",
    "df_user.rename(columns={'CatogoryID':'MostPvCatogory'},inplace=True)\n",
    "#把每个用户最多加购物车的商品类数据整理出来\n",
    "\n",
    "df_fav_count = df_fav.groupby(['UserID','CatogoryID']).ItemID.count().reset_index()\n",
    "df_fav_count.rename(columns={'ItemID':'CatogoryCounts'},inplace=True)\n",
    "df_fav_max = df_fav_count.groupby('UserID').CatogoryCounts.max().reset_index()\n",
    "df_fav_max.rename(columns={'CatogoryCounts':'FavoriteCatogory'},inplace=True)\n",
    "df_fav_count= pd.merge(df_fav_count,df_fav_max,how='left',on='UserID')\n",
    "df_fav_count['CatogoryID']=df_fav_count['CatogoryID'].astype(str)\n",
    "df_fav = df_fav_count.loc[df_fav_count['CatogoryCounts']==df_fav_count['FavoriteCatogory'],'CatogoryID'].groupby(df_fav_count['UserID']).aggregate(lambda x:','.join(x)).reset_index()\n",
    "df_user = pd.merge(df_user,df_fav,how='left',on='UserID')\n",
    "df_user.rename(columns={'CatogoryID':'MostFavCatogory'},inplace=True)\n",
    "#把每个用户最多收藏的商品类数据整理出来\n",
    "\n",
    "df_cart_count = df_cart.groupby(['UserID','CatogoryID']).ItemID.count().reset_index()\n",
    "df_cart_count.rename(columns={'ItemID':'CatogoryCounts'},inplace=True)\n",
    "df_cart_max = df_cart_count.groupby('UserID').CatogoryCounts.max().reset_index()\n",
    "df_cart_max.rename(columns={'CatogoryCounts':'FavoriteCatogory'},inplace=True)\n",
    "df_cart_count= pd.merge(df_cart_count,df_cart_max,how='left',on='UserID')\n",
    "df_cart_count['CatogoryID']=df_cart_count['CatogoryID'].astype(str)\n",
    "df_cart = df_cart_count.loc[df_cart_count['CatogoryCounts']==df_cart_count['FavoriteCatogory'],'CatogoryID'].groupby(df_cart_count['UserID']).aggregate(lambda x:','.join(x)).reset_index()\n",
    "df_user = pd.merge(df_user,df_cart,how='left',on='UserID')\n",
    "df_user.rename(columns={'CatogoryID':'MostCartCatogory'},inplace=True)\n",
    "#把每个用户最多购买的商品类数据整理出来\n",
    "\n",
    "df_buy_count = df_buy.groupby(['UserID','CatogoryID']).ItemID.count().reset_index()\n",
    "df_buy_count.rename(columns={'ItemID':'CatogoryCounts'},inplace=True)\n",
    "df_buy_max = df_buy_count.groupby('UserID').CatogoryCounts.max().reset_index()\n",
    "df_buy_max.rename(columns={'CatogoryCounts':'FavoriteCatogory'},inplace=True)\n",
    "df_buy_count= pd.merge(df_buy_count,df_buy_max,how='left',on='UserID')\n",
    "df_buy_count['CatogoryID']=df_buy_count['CatogoryID'].astype(str)\n",
    "df_buy = df_buy_count.loc[df_buy_count['CatogoryCounts']==df_buy_count['FavoriteCatogory'],'CatogoryID'].groupby(df_buy_count['UserID']).aggregate(lambda x:','.join(x)).reset_index()\n",
    "df_user = pd.merge(df_user,df_buy,how='left',on='UserID')\n",
    "df_user.rename(columns={'CatogoryID':'MostBuyCatogory'},inplace=True)\n",
    "df_user = df_user.fillna(0)\n",
    "#填充空值为0\n",
    "df_user.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.用户操作时间差分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the avarage time to buy items from cart to buy\n",
    "df_pv = df_Second.loc[df_Second['BehaviorType']=='pv',['UserID','ItemID','TimeStamps']]\n",
    "df_fav = df_Second.loc[df_Second['BehaviorType']=='fav',['UserID','ItemID','TimeStamps']]\n",
    "df_cart = df_Second.loc[df_Second['BehaviorType']=='cart',['UserID','ItemID','TimeStamps']]\n",
    "df_buy = df_Second.loc[df_Second['BehaviorType']=='buy',['UserID','ItemID','TimeStamps']]\n",
    "\n",
    "buy_cart=pd.merge(df_cart,df_buy,how='inner',on=['UserID','ItemID'],suffixes=('_cart','_buy'))\n",
    "buy_cart[\"time\"]=buy_cart[\"TimeStamps_buy\"]-buy_cart[\"TimeStamps_cart\"]\n",
    "\n",
    "buy_cart_time = buy_cart.loc[buy_cart['time']>0,'time'].mean()\n",
    "print(\"所有商品从加入购物车到被买下的平均时间\",int(buy_cart_time),\"s\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# find the avarage time to buy items from pv to buy\n",
    "df_pv = df_Second.loc[df_Second['BehaviorType']=='pv',['UserID','ItemID','TimeStamps']]\n",
    "df_fav = df_Second.loc[df_Second['BehaviorType']=='fav',['UserID','ItemID','TimeStamps']]\n",
    "df_cart = df_Second.loc[df_Second['BehaviorType']=='cart',['UserID','ItemID','TimeStamps']]\n",
    "df_buy = df_Second.loc[df_Second['BehaviorType']=='buy',['UserID','ItemID','TimeStamps']]\n",
    "\n",
    "df_pv=df_pv.groupby(['UserID','ItemID']).TimeStamps.min().reset_index().rename(columns={'TimeStamps':'TimeStamps'})\n",
    "buy_pv=pd.merge(df_pv,df_buy,how='inner',on=['UserID','ItemID'],suffixes=('_pv','_buy'))\n",
    "buy_pv[\"time\"]=buy_pv[\"TimeStamps_buy\"]-buy_pv[\"TimeStamps_pv\"]\n",
    "buy_pv_time = buy_pv.loc[buy_pv['time']>0,'time'].mean()\n",
    "print(\"所有商品从第一次浏览到被买下的平均时间\",int(buy_pv_time),\"s\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8.用户活跃时间段分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## 购买时间段\n",
    "time_buy = df_Second[df_Second['BehaviorType']=='buy'].groupby(['UserID','hour']).ItemID.count().reset_index()\n",
    "time_buy.rename(columns={'ItemID':'hour_counts'},inplace=True)\n",
    "time_buy_max = time_buy.groupby('UserID').hour_counts.max().reset_index()\n",
    "time_buy_max.rename(columns={'hour_counts':'buy_counts_max'},inplace=True)\n",
    "time_buy = pd.merge(time_buy,time_buy_max,how='left',on='UserID')\n",
    "time_buy_hour = time_buy.loc[time_buy['hour_counts']==time_buy['buy_counts_max'],['hour','UserID']].groupby(time_buy['UserID']).aggregate(lambda x:','.join(x)).reset_index()\n",
    "df_user = pd.merge(df_user,time_buy_hour,how = 'left',on='UserID')\n",
    "df_user.rename(columns={'hour':'timeBuy'},inplace=True)\n",
    "\n",
    "## 购买周几\n",
    "week_buy=df_Second[df_Second['BehaviorType']=='buy'].groupby(['UserID','weekday']).ItemID.count().reset_index()\n",
    "week_buy.rename(columns={'ItemID':'week_counts'},inplace=True)\n",
    "week_buy_max = week_buy.groupby('UserID').week_counts.max().reset_index()\n",
    "week_buy_max.rename(columns={'week_counts':'week_counts_max'},inplace=True)\n",
    "week_buy = pd.merge(week_buy,week_buy_max,how='left',on='UserID')\n",
    "week_buy['weekday']=week_buy['weekday'].astype(str)\n",
    "week_buy_date=week_buy.loc[week_buy['week_counts']==week_buy['week_counts_max'],'weekday'].groupby(week_buy['UserID']).aggregate(lambda x:','.join(x)).reset_index()\n",
    "week_buy_date.head()\n",
    "df_user = pd.merge(df_user,week_buy_date,how = 'left',on='UserID')\n",
    "df_user.rename(columns={'weekday':'weekBuy'},inplace=True)\n",
    "\n",
    "## 浏览时间段\n",
    "time_browser = df_Second[df_Second['BehaviorType']=='pv'].groupby(['UserID','hour']).ItemID.count().reset_index()\n",
    "time_browser.rename(columns={'ItemID':'hour_counts'},inplace=True)\n",
    "time_browser_max = time_browser.groupby('UserID').hour_counts.max().reset_index()\n",
    "time_browser_max.rename(columns={'hour_counts':'browser_counts_max'},inplace=True)\n",
    "time_browser = pd.merge(time_browser,time_browser_max,how='left',on='UserID')\n",
    "time_browser_hour = time_browser.loc[time_browser['hour_counts']==time_browser['browser_counts_max'],['hour','UserID']].groupby(time_browser['UserID']).aggregate(lambda x:','.join(x)).reset_index()\n",
    "df_user = pd.merge(df_user,time_browser_hour,how = 'left',on='UserID')\n",
    "df_user.rename(columns={'hour':'timebrowser'},inplace=True)\n",
    "time_browser_hour.head()\n",
    "time_buy_hour.head()\n",
    "## 购买周几\n",
    "week_browser=df_Second[df_Second['BehaviorType']=='pv'].groupby(['UserID','weekday']).ItemID.count().reset_index()\n",
    "week_browser.rename(columns={'ItemID':'week_counts'},inplace=True)\n",
    "week_browser_max = week_browser.groupby('UserID').week_counts.max().reset_index()\n",
    "week_browser_max.rename(columns={'week_counts':'week_counts_max'},inplace=True)\n",
    "week_browser = pd.merge(week_browser,week_browser_max,how='left',on='UserID')\n",
    "week_browser['weekday']=week_browser['weekday'].astype(str)\n",
    "week_browser_date=week_browser.loc[week_browser['week_counts']==week_browser['week_counts_max'],'weekday'].groupby(week_browser['UserID']).aggregate(lambda x:','.join(x)).reset_index()\n",
    "df_user = pd.merge(df_user,week_browser_date,how = 'left',on='UserID')\n",
    "df_user.rename(columns={'weekday':'weekbrowser'},inplace=True)\n",
    "df_user = df_user.fillna(0)\n",
    "df_user.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9.建立用户的RFM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "df_buy_1 = df_Second[df_Second['BehaviorType']=='buy']\n",
    "df_buy_1.head()\n",
    "Near_buy_tstamp = df_buy_1.groupby(by='UserID')['TimeStamps'].max() #得出用户最近购买时间\n",
    "df_buy_1 = pd.DataFrame(data=Near_buy_tstamp)\n",
    "diff_time = (endTime - Near_buy_tstamp).astype('int') #用户最近购买时间距离结束时间长短\n",
    "diff_day = (diff_time/(24*60*60)).astype('int')\n",
    "df_user['diffDay'] = diff_day\n",
    "df_user['diffDay'] = df_user['diffDay'].fillna(7)\n",
    "\n",
    "\n",
    "df_buy_2 = df_Second[df_Second['BehaviorType']=='buy']\n",
    "df_cart_2 = df_Second[df_Second['BehaviorType']=='cart']\n",
    "\n",
    "df_user['Frequency'] = df_buy_2['UserID'].value_counts().astype('int')\n",
    "df_user['Frequency'] = df_user['Frequency'].fillna(0)\n",
    "\n",
    "df_user['MonetaryValue'] = df_buy_2['UserID'].value_counts().astype('int') / df_cart_2['UserID'].value_counts().astype('int')\n",
    "df_user['MonetaryValue'] = df_user['MonetaryValue'].fillna(0)\n",
    "\n",
    "RFM = df_user[['UserID','diffDay','Frequency','MonetaryValue']]\n",
    "RFM.describe()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 10.对用户进行聚类分析"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RFM = RFM.replace(0, 0.01)\n",
    "RFM_log = RFM[['diffDay','Frequency','MonetaryValue']].apply(np.log,axis=1).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(RFM_log)\n",
    "RFM_normalization = scaler.transform(RFM_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# (使用肘部法则进行分析)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "from matplotlib.pyplot import subplots\n",
    "from sklearn.cluster import KMeans\n",
    "# k值的选择，1~8\n",
    "ks = range(1,9)\n",
    "inertias=[]\n",
    "for k in  ks:\n",
    "    kc = KMeans(n_clusters=k, init='k-means++', random_state = 1)\n",
    "    kc.fit(RFM_normalization)\n",
    "    inertias.append(kc.inertia_) # 样本距离其聚类中心的距离平方和\n",
    "\n",
    "    print('k=',k,' 迭代次数',kc.n_iter_)\n",
    "\n",
    "f,ax = subplots(figsize=(10,6))\n",
    "plt.plot(ks, inertias,'-o')\n",
    "plt.xlabel('Number of clusters')\n",
    "plt.ylabel('Sum of squared distances')\n",
    "plt.title('Elbow Criterion method to find best k')\n",
    "\n",
    "from sklearn import metrics\n",
    "kk = range(2,9)\n",
    "for k in kk:\n",
    "    y_pred = KMeans(n_clusters=k, random_state=1).fit_predict(RFM_normalization) #k必须大于1\n",
    "    calinski = metrics.calinski_harabasz_score(RFM_normalization, y_pred)\n",
    "    print('k:',k,'   calinski=',calinski)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# （选定聚类数目K， 继续进行聚类）"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "kc = KMeans(n_clusters=3, random_state=1).fit(RFM_normalization)\n",
    "\n",
    "cluster_label = kc.labels_\n",
    "RFM['K-means_label'] = cluster_label\n",
    "RFM.groupby(['K-means_label']).agg({'diffDay':'mean','Frequency':'mean','MonetaryValue':['mean','count']})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "RFM = RFM.drop(columns=['diffDay', 'Frequency', 'MonetaryValue'])\n",
    "df_user = pd.merge(df_user,RFM,how='left',on='UserID')\n",
    "df_user.rename(columns={'K-means_label':'UserLevel'},inplace=True)\n",
    "df_user['UserLevel'] = df_user['UserLevel'].replace(0,'一般用户')\n",
    "df_user['UserLevel'] = df_user['UserLevel'].replace(1,'发展用户')\n",
    "df_user['UserLevel'] = df_user['UserLevel'].replace(2,'重要用户')\n",
    "df_user.to_csv('../User.csv')\n",
    "df_user.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 11.数据写入数据库"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [
    {
     "ename": "OperationalError",
     "evalue": "(2003, \"Can't connect to MySQL server on '127.0.0.1' ([WinError 10061] 由于目标计算机积极拒绝，无法连接。)\")",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mConnectionRefusedError\u001B[0m                    Traceback (most recent call last)",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pymysql\\connections.py:613\u001B[0m, in \u001B[0;36mConnection.connect\u001B[1;34m(self, sock)\u001B[0m\n\u001B[0;32m    612\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 613\u001B[0m     sock \u001B[38;5;241m=\u001B[39m socket\u001B[38;5;241m.\u001B[39mcreate_connection(\n\u001B[0;32m    614\u001B[0m         (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mhost, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mport), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconnect_timeout, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs\n\u001B[0;32m    615\u001B[0m     )\n\u001B[0;32m    616\u001B[0m     \u001B[38;5;28;01mbreak\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\socket.py:844\u001B[0m, in \u001B[0;36mcreate_connection\u001B[1;34m(address, timeout, source_address)\u001B[0m\n\u001B[0;32m    843\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[1;32m--> 844\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m err\n\u001B[0;32m    845\u001B[0m \u001B[38;5;28;01mfinally\u001B[39;00m:\n\u001B[0;32m    846\u001B[0m     \u001B[38;5;66;03m# Break explicitly a reference cycle\u001B[39;00m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\socket.py:832\u001B[0m, in \u001B[0;36mcreate_connection\u001B[1;34m(address, timeout, source_address)\u001B[0m\n\u001B[0;32m    831\u001B[0m     sock\u001B[38;5;241m.\u001B[39mbind(source_address)\n\u001B[1;32m--> 832\u001B[0m \u001B[43msock\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43msa\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m    833\u001B[0m \u001B[38;5;66;03m# Break explicitly a reference cycle\u001B[39;00m\n",
      "\u001B[1;31mConnectionRefusedError\u001B[0m: [WinError 10061] 由于目标计算机积极拒绝，无法连接。",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001B[1;31mOperationalError\u001B[0m                          Traceback (most recent call last)",
      "Input \u001B[1;32mIn [17]\u001B[0m, in \u001B[0;36m<cell line: 67>\u001B[1;34m()\u001B[0m\n\u001B[0;32m     64\u001B[0m     cursor1\u001B[38;5;241m.\u001B[39mclose()\n\u001B[0;32m     65\u001B[0m     conn\u001B[38;5;241m.\u001B[39mclose()\n\u001B[1;32m---> 67\u001B[0m \u001B[43mmain\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdatamining\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdata\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m\n",
      "Input \u001B[1;32mIn [17]\u001B[0m, in \u001B[0;36mmain\u001B[1;34m(db_name, table_name)\u001B[0m\n\u001B[0;32m     61\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mmain\u001B[39m(db_name,table_name):\n\u001B[1;32m---> 62\u001B[0m     conn, cursor1 \u001B[38;5;241m=\u001B[39m\u001B[43minsertData\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdb_name\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtable_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     63\u001B[0m     \u001B[38;5;66;03m# 当添加完成之后需要关闭我们的游标，以及与mysql的连接\u001B[39;00m\n\u001B[0;32m     64\u001B[0m     cursor1\u001B[38;5;241m.\u001B[39mclose()\n",
      "Input \u001B[1;32mIn [17]\u001B[0m, in \u001B[0;36minsertData\u001B[1;34m(db_name, table_name)\u001B[0m\n\u001B[0;32m     28\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21minsertData\u001B[39m(db_name,table_name):\n\u001B[1;32m---> 29\u001B[0m     conn,cursor1\u001B[38;5;241m=\u001B[39m\u001B[43mgetcon\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdb_name\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     30\u001B[0m     \u001B[38;5;66;03m# 使用pandas 读取csv文件\u001B[39;00m\n\u001B[0;32m     31\u001B[0m     df\u001B[38;5;241m=\u001B[39mpd\u001B[38;5;241m.\u001B[39mread_csv(\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m../User.csv\u001B[39m\u001B[38;5;124m'\u001B[39m)\n",
      "Input \u001B[1;32mIn [17]\u001B[0m, in \u001B[0;36mgetcon\u001B[1;34m(db_name)\u001B[0m\n\u001B[0;32m     13\u001B[0m server\u001B[38;5;241m.\u001B[39mstart()\n\u001B[0;32m     14\u001B[0m \u001B[38;5;66;03m# 云服务器上mysql数据库连接\u001B[39;00m\n\u001B[1;32m---> 15\u001B[0m conn \u001B[38;5;241m=\u001B[39m \u001B[43mpymysql\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43mhost\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43m127.0.0.1\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# 此处必须是是127.0.0.1\u001B[39;49;00m\n\u001B[0;32m     16\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mport\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m3306\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[0;32m     17\u001B[0m \u001B[43m                  \u001B[49m\u001B[43muser\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mdatamining\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# mysql的登录账号admin\u001B[39;49;00m\n\u001B[0;32m     18\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mpassword\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mN3df8M6FM2Da8Rmn\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# mysql的登录密码pwd\u001B[39;49;00m\n\u001B[0;32m     19\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mdb\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mdatamining\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m  \u001B[49m\u001B[38;5;66;43;03m# mysql中要访问的数据表\u001B[39;49;00m\n\u001B[0;32m     20\u001B[0m \u001B[43m                  \u001B[49m\u001B[43mcharset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[38;5;124;43mutf8\u001B[39;49m\u001B[38;5;124;43m'\u001B[39;49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# 表的字符集\u001B[39;00m\n\u001B[0;32m     21\u001B[0m \u001B[38;5;66;03m# host是选择连接哪的数据库localhost是本地数据库，port是端口号默认3306\u001B[39;00m\n\u001B[0;32m     22\u001B[0m \u001B[38;5;66;03m#user是使用的人的身份，root是管理员身份，passwd是密码。db是数据库的名称，charset是编码格式\u001B[39;00m\n\u001B[0;32m     23\u001B[0m \u001B[38;5;66;03m# conn=pymysql.connect(host=\"106.55.99.98\",port=3306,user='DataMining',passwd='5zWtmZwi27kFYHH2',db=db_name,charset='utf8')\u001B[39;00m\n\u001B[0;32m     24\u001B[0m \u001B[38;5;66;03m# 创建游标对象\u001B[39;00m\n\u001B[0;32m     25\u001B[0m cursor1\u001B[38;5;241m=\u001B[39mconn\u001B[38;5;241m.\u001B[39mcursor()\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pymysql\\connections.py:353\u001B[0m, in \u001B[0;36mConnection.__init__\u001B[1;34m(self, user, password, host, database, unix_socket, port, charset, sql_mode, read_default_file, conv, use_unicode, client_flag, cursorclass, init_command, connect_timeout, read_default_group, autocommit, local_infile, max_allowed_packet, defer_connect, auth_plugin_map, read_timeout, write_timeout, bind_address, binary_prefix, program_name, server_public_key, ssl, ssl_ca, ssl_cert, ssl_disabled, ssl_key, ssl_verify_cert, ssl_verify_identity, compress, named_pipe, passwd, db)\u001B[0m\n\u001B[0;32m    351\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sock \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n\u001B[0;32m    352\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m--> 353\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mconnect\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\AppData\\Local\\Programs\\Python\\Python39\\lib\\site-packages\\pymysql\\connections.py:664\u001B[0m, in \u001B[0;36mConnection.connect\u001B[1;34m(self, sock)\u001B[0m\n\u001B[0;32m    662\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m DEBUG:\n\u001B[0;32m    663\u001B[0m         \u001B[38;5;28mprint\u001B[39m(exc\u001B[38;5;241m.\u001B[39mtraceback)\n\u001B[1;32m--> 664\u001B[0m     \u001B[38;5;28;01mraise\u001B[39;00m exc\n\u001B[0;32m    666\u001B[0m \u001B[38;5;66;03m# If e is neither DatabaseError or IOError, It's a bug.\u001B[39;00m\n\u001B[0;32m    667\u001B[0m \u001B[38;5;66;03m# But raising AssertionError hides original error.\u001B[39;00m\n\u001B[0;32m    668\u001B[0m \u001B[38;5;66;03m# So just reraise it.\u001B[39;00m\n\u001B[0;32m    669\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m\n",
      "\u001B[1;31mOperationalError\u001B[0m: (2003, \"Can't connect to MySQL server on '127.0.0.1' ([WinError 10061] 由于目标计算机积极拒绝，无法连接。)\")"
     ]
    }
   ],
   "source": [
    "from sshtunnel import SSHTunnelForwarder\n",
    "import pymysql\n",
    "\n",
    "def getcon():\n",
    "    server = SSHTunnelForwarder(\n",
    "\tssh_address_or_host=(\"云服务器地址IP\", 22),\n",
    "\tssh_username='云服务器登录账号admin',\n",
    "\tssh_password='云服务器登录密码password',\n",
    "\tremote_bind_address=('localhost', 3306)\n",
    ")\n",
    "\n",
    "    # 云服务器开启\n",
    "    server.start()\n",
    "    # 云服务器上mysql数据库连接\n",
    "    conn = pymysql.connect(host='127.0.0.1',\n",
    "                      port=3306,\n",
    "                      user='mysql的登录账号admin',\n",
    "                      password='mysql的登录密码pwd',\n",
    "                      db=\"mysql中要访问的数据表\",\n",
    "                      charset='utf8')\n",
    "    cursor1=conn.cursor()\n",
    "    return conn,cursor1\n",
    "\n",
    "def insertData(table_name):\n",
    "    conn,cursor1=getcon()\n",
    "    df=pd.read_csv('../User.csv')\n",
    "    counts = 0\n",
    "    for each in df.values:\n",
    "        sql = 'insert into '+table_name+' values('\n",
    "        for i,n in enumerate(each):\n",
    "            if i < (len(each) - 1):\n",
    "                if i<=4 or i==8 or i==9:\n",
    "                    sql = sql+ str(n) + ','\n",
    "                else:\n",
    "                    sql = sql + '\"' + str(n) + '\"' + ','\n",
    "            else:\n",
    "                sql = sql + '\"' + str(n) + '\"'\n",
    "        sql = sql + ');'\n",
    "        cursor1.execute(sql)\n",
    "        conn.commit()\n",
    "        counts+=1\n",
    "\n",
    "def main(table_name):\n",
    "    conn, cursor1 =insertData(table_name)\n",
    "    cursor1.close()\n",
    "    conn.close()\n",
    "\n",
    "main('data')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# 12.商品推荐"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "user_id=100\n",
    "user_pv=df_Second[df_Second['UserID']==user_id]['ItemID'].value_counts().reset_index()\n",
    "user_pv.rename(columns={'ItemID':'pv_counts','index':'ItemID'},inplace=True)\n",
    "\n",
    "# 获得相似的用户和用户相似度\n",
    "sim_user=pd.merge(user_pv,df_Second[['UserID', 'ItemID']],how='inner',on=['ItemID'])\n",
    "sim_user_pv=sim_user.groupby('UserID').sum()['pv_counts'].reset_index()\n",
    "sim_user_pv.sort_values(by='pv_counts',ascending=False,inplace=True)\n",
    "sim_user_pv=sim_user_pv.reset_index(drop=True).rename(columns={'pv_counts':'similarity'})\n",
    "sim_user_pv=sim_user_pv.loc[sim_user_pv['UserID']!=user_id]\n",
    "sim_user_pv\n",
    "\n",
    "# 根据相似用户计算相似商品\n",
    "sim_item=pd.merge(sim_user_pv,df_Second[['UserID', 'ItemID']],how='inner',on=['UserID'])\n",
    "sim_item\n",
    "sim_item_pv=sim_item.groupby('ItemID').sum()['similarity'].reset_index()\n",
    "sim_item_pv.sort_values(by='similarity',ascending=False,inplace=True)\n",
    "sim_item_pv=sim_item_pv.reset_index(drop=True)\n",
    "sim_item_pv[0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.rcParams['font.family'] = ['sans-serif']\n",
    "plt.rcParams['font.sans-serif'] = ['SimHei']\n",
    "X = RFM_normalization[:987991]\n",
    "print(X)\n",
    "Y = KMeans(n_clusters=3, random_state=9).fit_predict(X)\n",
    "plt.scatter(X[:, 0], X[:, 1],X[:, 2], c=Y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 13.数据可视化"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "from pyecharts import options as opts\n",
    "from pyecharts.charts import Pie, Funnel\n",
    "from pyecharts.render import make_snapshot\n",
    "from snapshot_selenium import snapshot\n",
    "\n",
    "\n",
    "jiti = ['一般用户', '发展用户', '重要用户']\n",
    "num = [335521,484401,168069]\n",
    "c = (\n",
    "    Pie()\n",
    "    .add(\"客户占比\", [list(z) for z in zip(jiti,num)])\n",
    "    .set_global_opts(title_opts=opts.TitleOpts(title=\"客户数量占比\"))\n",
    "    .set_series_opts(label_opts=opts.LabelOpts(formatter=\"{b}: {c}\"))\n",
    "    .render(\"pie_daishi_user.html\")\n",
    ")\n",
    "\n",
    "make_snapshot(snapshot,c,'客户数量占比.png')\n",
    "\n",
    "\n",
    "jiti = ['浏览', '收藏和加购物车', '购买']\n",
    "num = [100,9.3,2.2]\n",
    "\n",
    "c = (\n",
    "    Funnel()\n",
    "    .add(\"占比\", [list(z) for z in zip(jiti,num)])\n",
    "    .set_global_opts(title_opts=opts.TitleOpts(title=\"用户漏斗转换模型\"))\n",
    "    .set_series_opts(label_opts=opts.LabelOpts(formatter=\"{c} %\"))\n",
    "    .render(\"pie_daishi_trans.html\")\n",
    ")\n",
    "\n",
    "make_snapshot(snapshot,c,'用户转化比例.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pyecharts.options as opts\n",
    "from pyecharts.charts import Line\n",
    "x=['11-25','11-26','11-27','11-28','11-29','11-30','12-01','12-02','12-03']\n",
    "y1=[9353415, 9567422, 9041186, 8842932, 9210818, 9358998, 9718956, 12329640, 12237300]\n",
    "y2=[302071, 308954, 291221, 289100, 298587, 302264, 307115, 396749, 392197]\n",
    "y3=[563376, 582581, 541904, 534157, 551593, 565015, 623346, 793568, 774905]\n",
    "y4=[201144, 205638, 226834, 211997, 223068, 221459, 210010, 257903, 257754]\n",
    "line_1=(\n",
    "    Line()\n",
    "    .add_xaxis(xaxis_data=x)\n",
    "    .add_yaxis(series_name=\"浏览\",y_axis=y1)\n",
    "    .add_yaxis(series_name=\"收藏\",y_axis=y2)\n",
    "    .add_yaxis(series_name=\"加购\",y_axis=y3)\n",
    "    .add_yaxis(series_name=\"购买\",y_axis=y4)\n",
    "    .set_global_opts(title_opts=opts.TitleOpts(title=\"各行为数量\"))\n",
    "    .render(\"pie_daishi_1.html\")\n",
    ")\n",
    "line_2=(\n",
    "    Line()\n",
    "    .add_xaxis(xaxis_data=x)\n",
    "    .add_yaxis(series_name=\"收藏\",y_axis=y2)\n",
    "    .add_yaxis(series_name=\"加购\",y_axis=y3)\n",
    "    .add_yaxis(series_name=\"购买\",y_axis=y4)\n",
    "    .set_global_opts(title_opts=opts.TitleOpts(title=\"各行为数量\"))\n",
    "    .render(\"pie_daishi_2.html\")\n",
    ")\n",
    "make_snapshot(snapshot,line_1,'Day统计_1.png')\n",
    "make_snapshot(snapshot,line_2,'Day统计_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "import pyecharts.options as opts\n",
    "from pyecharts.charts import Line\n",
    "x=['morning','forenoon','noon','afternoon','night']\n",
    "y1=[6804190, 14561262, 13123245, 22573411, 32598559]\n",
    "y2=[237015, 494639, 437118, 719497, 999989]\n",
    "y3=[411727, 917240, 796471, 1348932, 2056075]\n",
    "y4=[115864, 344675, 364063, 558550, 632655]\n",
    "line_1=(\n",
    "    Line()\n",
    "    .add_xaxis(xaxis_data=x)\n",
    "    .add_yaxis(series_name=\"浏览\",y_axis=y1)\n",
    "    .add_yaxis(series_name=\"收藏\",y_axis=y2)\n",
    "    .add_yaxis(series_name=\"加购\",y_axis=y3)\n",
    "    .add_yaxis(series_name=\"购买\",y_axis=y4)\n",
    "    .set_global_opts(title_opts=opts.TitleOpts(title=\"各行为数量\"))\n",
    "    .render(\"pie_daishi_3.html\")\n",
    ")\n",
    "line_2=(\n",
    "    Line()\n",
    "    .add_xaxis(xaxis_data=x)\n",
    "    .add_yaxis(series_name=\"收藏\",y_axis=y2)\n",
    "    .add_yaxis(series_name=\"加购\",y_axis=y3)\n",
    "    .add_yaxis(series_name=\"购买\",y_axis=y4)\n",
    "    .set_global_opts(title_opts=opts.TitleOpts(title=\"各行为数量\"))\n",
    "    .render(\"pie_daishi_4.html\")\n",
    ")\n",
    "make_snapshot(snapshot,line_1,'Hour统计_1.png')\n",
    "make_snapshot(snapshot,line_2,'Hour统计_2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b3ba2566441a7c06988d0923437866b63cedc61552a5af99d1f4fb67d367b25f"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}